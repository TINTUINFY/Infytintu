{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a712d76",
   "metadata": {},
   "source": [
    "#  prediction of address from the Invoice using LayoutLm model trained with Amazon and Flipkart Invoice details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0694eb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from layoutlm_preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e478a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05d71416",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = 'C:/Users/tintu.thomas02/AppData/Local/Tesseract-OCR/tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe8381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = convert_from_path('invoice.pdf',poppler_path=r\"C:\\Users\\tintu.thomas02\\Downloads\\Release-22.04.0-0 (1)\\poppler-22.04.0\\Library\\bin\")\n",
    "for image in pages:\n",
    "    image.save('output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d9ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "def get_labels(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        labels = f.read().splitlines()\n",
    "    if \"O\" not in labels:\n",
    "        labels = [\"O\"] + labels\n",
    "    return labels\n",
    "\n",
    "labels = get_labels(\"Invoiceannotation/labels.txt\")\n",
    "num_labels = len(labels)\n",
    "label_map = {i: label for i, label in enumerate(labels)}\n",
    "# Use cross entropy ignore index as padding label id so that only real label ids contribute to the loss later\n",
    "pad_token_label_id = CrossEntropyLoss().ignore_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8571bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/layoutlm-base-uncased were not used when initializing LayoutLMForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing LayoutLMForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LayoutLMForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LayoutLMForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlm-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH='./layoutlmnew15.pt'\n",
    "models = LayoutLMForTokenClassification.from_pretrained(\"microsoft/layoutlm-base-uncased\", num_labels=num_labels)\n",
    "models.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7c56da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 34, 34, 34, 34, 34, 10, 20, 20, 29, 29, 29, 19, 29, 29, 29, 29, 19, 29, 29, 29, 29, 11, 21, 29, 29, 11, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 21, 29, 29, 29, 29, 21, 29, 29, 29, 29, 29, 29, 21, 29, 29, 29, 29, 29, 29, 29, 29, 29, 21, 29, 29, 21, 29, 29, 29, 36, 36, 29, 19, 29, 29, 31, 29, 31, 31, 31, 6, 36, 16, 31, 33, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 6, 6, 26, 16, 16, 31, 31, 31, 31, 31, 36, 31, 16, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 36, 31, 16, 31, 31, 31, 31, 31, 31, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 38, 38, 38, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 21, 32, 32, 32, 32, 21, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 21, 32, 21, 32, 32, 32, 32, 32, 32, 32, 32, 37, 32, 38, 38, 38, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 21, 37, 37, 37, 37, 37, 21, 37, 37, 37, 37, 37, 37, 37, 37, 21, 37, 21, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 36, 36, 36, 36, 31, 31, 31, 31, 31, 31, 31, 31, 31, 36, 36, 36, 36, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 36, 36, 36, 36, 31, 31, 31, 31, 31, 31, 31, 36, 36, 31, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 31, 31, 31, 31, 31, 31, 11, 11, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 36, 36, 36, 36, 36, 36, 31, 31, 31, 31, 31, 31, 31, 31, 31, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 31, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 31, 31, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 31, 31, 31, 31, 31, 31, 11, 31, 31, 31, 31, 31, 31, 31, 11, 31, 31, 31, 31, 31, 31, 31, 31, 11, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 11, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 4, 24, 24, 24, 34, 34, 34, 4, 14, 34, 36, 36, 36, 36, 36, 36, 36, 36, 36, 31, 31, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 34, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 31, 36]\n"
     ]
    }
   ],
   "source": [
    "image, words, boxes, actual_boxes = preprocess(\"output.png\")\n",
    "word_level_predictions, final_boxes=convert_to_features(image, words, boxes, actual_boxes, models)\n",
    "draw = ImageDraw.Draw(image)\n",
    "font = ImageFont.load_default()\n",
    "def iob_to_label(label):\n",
    "    if label != 'O':\n",
    "        return label[2:]\n",
    "    else:\n",
    "        return \"\"\n",
    "label2color = {'QUESTION':'blue','question':'blue','ANSWER':'green','answer':'green','BILLING_ADDRESS_HEADER':'orange','billing_address_header':'orange','BILLINGADDRESSDETAILS':'violet','billingaddressdetails':'violet','HEADER':'red','SOLDBYHEADER':'black','soldbyheader':'black','SOLDBYDETAILS':'green','soldbydetails':'green','SHIPPINGADDRESSHEADER':'yellow','shippingaddressheader':'yellow','SHIPPINGADDRESSDETAILS':'magenta','shippingaddressdetails':'magenta','OTHERS':'black','':'violet','header':'red','others':'black'}\n",
    "# label2color = {'question':'blue', 'answer':'green', 'header':'orange', '':'violet'}\n",
    "for prediction, box in zip(word_level_predictions, final_boxes):\n",
    "    predicted_label = iob_to_label(label_map[prediction]).lower()\n",
    "    draw.rectangle(box, outline=label2color[predicted_label])\n",
    "    draw.text((box[0] + 10, box[1] - 10), text=predicted_label, fill=label2color[predicted_label], font=font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b4b90ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tintu\n",
      "\n",
      "Thomas\n",
      "\n",
      "Malabar\n",
      "\n",
      "\n",
      "Hostel,\n",
      "\n",
      "Hostel,\n",
      "\n",
      "Kalavath\n",
      "\n",
      "Road,\n",
      "\n",
      "Palarivattom,\n",
      "\n",
      "Opposite\n",
      "\n",
      "To\n",
      "\n",
      "Powerskill\n",
      "\n",
      "Engineering\n",
      "\n",
      "Solutions\n",
      "\n",
      "Pvt\n",
      "\n",
      "Limited\n",
      "\n",
      "Ernakulam,\n",
      "\n",
      "KERALA,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Code:32\n",
      "\n",
      "Code:32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "def bounding_box_img(img,bbox):\n",
    "            x_min, y_min, x_max, y_max = bbox\n",
    "            bbox_obj = img[y_min-4:y_max+4, x_min-4:x_max+4]\n",
    "            return bbox_obj\n",
    "flag = 0\n",
    "# iob_to_label(label_map[word_level_predictions[i]]).lower() == \"billing_address_header\" or \n",
    "img = cv2.imread(\"output.png\")\n",
    "for i in range(len(word_level_predictions)):\n",
    "    if iob_to_label(label_map[word_level_predictions[i]]).lower() == \"billingaddressdetails\":\n",
    "        cropped_img = bounding_box_img(img,final_boxes[i])\n",
    "        text = pytesseract.image_to_string(cropped_img)\n",
    "        print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
